{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0432da6-90ca-4c85-9ecb-c9cfba0ca32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bf5ec9-9b41-4c9c-a106-d38f8f07c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/roger/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495d35d-95a5-46d8-be3b-6e4146fe3d2c",
   "metadata": {},
   "source": [
    "# Data retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfa050-c73c-4042-9968-8058c8c2282e",
   "metadata": {},
   "source": [
    "## Create dataframes\n",
    "\n",
    "> One dataframe containing numeric data, and another one with text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95134c9-8937-435d-851d-6372f5d8a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numeric = pd.DataFrame(columns=['following', 'followers', 'username_length', 'full_name_length', 'description_length', 'username_has_number', 'full_name_has_number', 'description_has_number', 'is_fake'])\n",
    "dataset_text = pd.DataFrame(columns=['username', 'full_name', 'description', 'is_fake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df02bf-e26e-4851-ba5a-dee1189025a1",
   "metadata": {},
   "source": [
    "## Load file & parse json data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d152a3-6c87-4b77-a328-d1ed5d415ff0",
   "metadata": {},
   "source": [
    "#### Process fake account data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b20bdad-e3cc-4882-ba34-95cef7ef2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.scandir('data/fake'):\n",
    "    if filename.is_file():\n",
    "        fake_data_file = open(filename.path)\n",
    "        fake_json = json.load(fake_data_file)\n",
    "        user_data = fake_json['graphql']['user']\n",
    "\n",
    "        following = user_data['edge_follow']['count']\n",
    "        followers = user_data['edge_followed_by']['count']\n",
    "\n",
    "        username_text = user_data['username']\n",
    "        full_name_text = user_data['full_name']\n",
    "        description_text = user_data['biography']\n",
    "        \n",
    "        username_length = len(user_data['username'])\n",
    "        full_name_length = len(user_data['full_name'])\n",
    "        description_length = len(user_data['biography'])\n",
    "        \n",
    "        username_has_number = any(char.isdigit() for char in user_data['username'])\n",
    "        full_name_has_number = any(char.isdigit() for char in user_data['full_name'])\n",
    "        description_has_number = any(char.isdigit() for char in user_data['biography'])\n",
    "        \n",
    "        is_fake = True\n",
    "        \n",
    "        row_numeric = {\n",
    "            'following': following,\n",
    "            'followers': followers,\n",
    "            'username_length': username_length,\n",
    "            'full_name_length': full_name_length, \n",
    "            'description_length': description_length, \n",
    "            'username_has_number': username_has_number, \n",
    "            'full_name_has_number': full_name_has_number,\n",
    "            'description_has_number': description_has_number, \n",
    "            'is_fake': is_fake\n",
    "        }\n",
    "\n",
    "        row_text = {\n",
    "            'username': username_text,\n",
    "            'full_name': full_name_text,\n",
    "            'description': description_text,\n",
    "            'is_fake': is_fake\n",
    "        }\n",
    "        \n",
    "        dataset_numeric = pd.concat([dataset_numeric, pd.DataFrame([row_numeric])], ignore_index=True)\n",
    "        dataset_text = pd.concat([dataset_text, pd.DataFrame([row_text])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a1355-d417-4e7f-9ad2-828b6be80ca7",
   "metadata": {},
   "source": [
    "#### Process real account data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c825a7a-a7bb-4d72-bd6f-a1b1ada76bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.scandir('data/real'):\n",
    "    if filename.is_file():\n",
    "        real_data_file = open(filename.path)\n",
    "        real_json = json.load(real_data_file)\n",
    "\n",
    "        following = real_json['numberFollowing']\n",
    "        followers = real_json['numberFollowers']\n",
    "        \n",
    "        username_length = len(real_json['alias'])\n",
    "        username_has_number = any(char.isdigit() for char in real_json['alias'])\n",
    "        username_text = real_json['alias']\n",
    "        \n",
    "        full_name = real_json['username']\n",
    "        if full_name is not None:\n",
    "            full_name_length = len(full_name)\n",
    "            full_name_has_number = any(char.isdigit() for char in full_name)\n",
    "            full_name_text = full_name\n",
    "        else:\n",
    "            full_name_length = 0\n",
    "            full_name_has_number = False\n",
    "\n",
    "        description = real_json['descriptionProfile']\n",
    "        if description is not None:\n",
    "            description_length = len(description[0])\n",
    "            description_has_number = any(char.isdigit() for char in description[0])\n",
    "            description_text = description[0]\n",
    "        else:\n",
    "            description_length = 0\n",
    "            description_has_number = False\n",
    "\n",
    "        is_fake = False\n",
    "\n",
    "        row_numeric = {\n",
    "            'following': following,\n",
    "            'followers': followers,\n",
    "            'username_length': username_length,\n",
    "            'full_name_length': full_name_length, \n",
    "            'description_length': description_length, \n",
    "            'username_has_number': username_has_number, \n",
    "            'full_name_has_number': full_name_has_number,\n",
    "            'description_has_number': description_has_number, \n",
    "            'is_fake': is_fake\n",
    "        }\n",
    "\n",
    "        row_text = {\n",
    "            'username': username_text,\n",
    "            'full_name': full_name_text,\n",
    "            'description': description_text,\n",
    "            'is_fake': is_fake\n",
    "        }\n",
    "        \n",
    "        dataset_numeric = pd.concat([dataset_numeric, pd.DataFrame([row_numeric])], ignore_index=True)\n",
    "        dataset_text = pd.concat([dataset_text, pd.DataFrame([row_text])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75463a16-8845-4c9d-beb3-22d29f09585c",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795afca-b2b0-4d9f-bc95-8d97335685af",
   "metadata": {},
   "source": [
    "## Min-Max normalization of the numeric dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e0f236-57cf-4b3b-a712-a482f7dd0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numeric = (dataset_numeric-dataset_numeric.min())/(dataset_numeric.max()-dataset_numeric.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c19ae-c967-4f29-9ae3-71330ff2bb02",
   "metadata": {},
   "source": [
    "## Remove empty descriptions of the text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43fc6ff2-3e6e-4f1e-b174-8a5b293b75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text = dataset_text[dataset_text['description'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01069164-38c1-4499-9a9b-0c3d905a0ed1",
   "metadata": {},
   "source": [
    "## Translate descriptions to english\n",
    "\n",
    "> Use wisely, API consumes money from google cloud free trial ($300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470a319b-e148-4e64-a9e3-8f461bba09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for index, row in dataset_text.iterrows():\n",
    "    body = {\n",
    "        'q': row['description'],\n",
    "        'target': 'en',\n",
    "        'key': 'AIzaSyAGzUMVuHzalVmFJsoBN9jyQZWHs2aY1Kg'\n",
    "    }\n",
    "    \n",
    "    res = requests.post('https://translation.googleapis.com/language/translate/v2?key=AIzaSyAGzUMVuHzalVmFJsoBN9jyQZWHs2aY1Kg', json=body)\n",
    "    res_json = json.loads(res.text)\n",
    "    translated_text = res_json['data']['translations'][0]['translatedText']\n",
    "\n",
    "    cleaned_text = re.sub('[^a-zA-Z0-9\\s]', '', translated_text).lower()\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    word_tokens = word_tokenize(cleaned_text)\n",
    "    array_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in array_sentence]\n",
    "    text = ' '.join(lemmatized_tokens)\n",
    "    no_url_text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "\n",
    "    dataset_text.at[index, 'description'] = no_url_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c02b823-83b6-46cf-b01d-da195eaffc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text = dataset_text[dataset_text['description'].str.len() > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ccf43-c7de-4541-8c8b-b1e3da03278b",
   "metadata": {},
   "source": [
    "## Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc522fef-5821-4caa-897d-0d58a591f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset_numeric.groupby('is_fake')\n",
    "balanced_dataset_numeric = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "\n",
    "g = dataset_text.groupby('is_fake')\n",
    "balanced_dataset_text = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02c84c-80bc-4b5a-a348-f5b48d785c4c",
   "metadata": {},
   "source": [
    "# Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e71321-dc34-44b0-805f-6fee2afcf334",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset_numeric.to_csv('data/dataset_numeric.csv', index=False)\n",
    "balanced_dataset_text.to_csv('data/dataset_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ccb514-9c68-4bc3-b841-bf5b6da41ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>takpar7173</td>\n",
       "      <td>takpar----üòé</td>\n",
       "      <td>horn cow special complex high flag person some...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ali_nourifard</td>\n",
       "      <td>Ali noorifard</td>\n",
       "      <td>buy training package contact 09126541637 page ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>narmak_ma</td>\n",
       "      <td>ŸÜÿßÿ±ŸÖ⁄© ŸÖÿß</td>\n",
       "      <td>page resident lover old narmak neighborhood fo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>khajeh1984</td>\n",
       "      <td>Mohammad Khajeh</td>\n",
       "      <td>well away filthy world look deed death near god</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>_lli9k</td>\n",
       "      <td>ÿ™ÿ±ŸÅ.</td>\n",
       "      <td>long drawing alive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>mauricetravelphotos</td>\n",
       "      <td>Travel ‚Ä¢ Nature ‚Ä¢ Vacation</td>\n",
       "      <td>travel world cheapest ticket</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>whereloveisillegal</td>\n",
       "      <td>Where Love Is Illegal</td>\n",
       "      <td>documenting sharing lgbtiq story survival arou...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>aka.the.one</td>\n",
       "      <td>LUNA I'NOORüåô</td>\n",
       "      <td>lifestyle vlogs business inquires lunainoorgma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>songofstyle</td>\n",
       "      <td>Aimee Song</td>\n",
       "      <td>ahmee rhyme mommy new york time bestselling au...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>lizaonair</td>\n",
       "      <td>‚òÖ Lizaonair</td>\n",
       "      <td>youtube beauty blogger</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1204 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 username                   full_name  \\\n",
       "3              takpar7173                 takpar----üòé   \n",
       "7           ali_nourifard               Ali noorifard   \n",
       "10              narmak_ma                    ŸÜÿßÿ±ŸÖ⁄© ŸÖÿß   \n",
       "11             khajeh1984             Mohammad Khajeh   \n",
       "18                 _lli9k                        ÿ™ÿ±ŸÅ.   \n",
       "...                   ...                         ...   \n",
       "1666  mauricetravelphotos  Travel ‚Ä¢ Nature ‚Ä¢ Vacation   \n",
       "1667   whereloveisillegal       Where Love Is Illegal   \n",
       "1668          aka.the.one                LUNA I'NOORüåô   \n",
       "1669          songofstyle                  Aimee Song   \n",
       "1670            lizaonair                 ‚òÖ Lizaonair   \n",
       "\n",
       "                                            description is_fake  \n",
       "3     horn cow special complex high flag person some...    True  \n",
       "7     buy training package contact 09126541637 page ...    True  \n",
       "10    page resident lover old narmak neighborhood fo...    True  \n",
       "11      well away filthy world look deed death near god    True  \n",
       "18                                   long drawing alive    True  \n",
       "...                                                 ...     ...  \n",
       "1666                       travel world cheapest ticket   False  \n",
       "1667  documenting sharing lgbtiq story survival arou...   False  \n",
       "1668  lifestyle vlogs business inquires lunainoorgma...   False  \n",
       "1669  ahmee rhyme mommy new york time bestselling au...   False  \n",
       "1670                             youtube beauty blogger   False  \n",
       "\n",
       "[1204 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7203d02-167a-488d-a73e-a8de946e71b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
