{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0432da6-90ca-4c85-9ecb-c9cfba0ca32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bf5ec9-9b41-4c9c-a106-d38f8f07c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/roger/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495d35d-95a5-46d8-be3b-6e4146fe3d2c",
   "metadata": {},
   "source": [
    "# Data retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfa050-c73c-4042-9968-8058c8c2282e",
   "metadata": {},
   "source": [
    "## Create dataframes\n",
    "\n",
    "> One dataframe containing numeric data, and another one with text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95134c9-8937-435d-851d-6372f5d8a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_numeric = pd.DataFrame(columns=['following', 'followers', 'username_length', 'full_name_length', 'description_length', 'username_has_number', 'full_name_has_number', 'description_has_number', 'is_fake'])\n",
    "# dataset_text = pd.DataFrame(columns=['username', 'full_name', 'description', 'is_fake'])\n",
    "dataset_mix = pd.DataFrame(columns=['following', 'followers', 'username_length', 'full_name_length', 'description_length', 'username_has_number', 'full_name_has_number', 'description_has_number', 'username', 'full_name', 'description', 'is_fake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df02bf-e26e-4851-ba5a-dee1189025a1",
   "metadata": {},
   "source": [
    "## Load file & parse json data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d152a3-6c87-4b77-a328-d1ed5d415ff0",
   "metadata": {},
   "source": [
    "#### Process fake account data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b20bdad-e3cc-4882-ba34-95cef7ef2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.scandir('data/fake'):\n",
    "    if filename.is_file():\n",
    "        fake_data_file = open(filename.path)\n",
    "        fake_json = json.load(fake_data_file)\n",
    "        user_data = fake_json['graphql']['user']\n",
    "\n",
    "        following = user_data['edge_follow']['count']\n",
    "        followers = user_data['edge_followed_by']['count']\n",
    "\n",
    "        username_text = user_data['username']\n",
    "        full_name_text = user_data['full_name']\n",
    "        description_text = user_data['biography']\n",
    "        \n",
    "        username_length = len(user_data['username'])\n",
    "        full_name_length = len(user_data['full_name'])\n",
    "        description_length = len(user_data['biography'])\n",
    "        \n",
    "        username_has_number = any(char.isdigit() for char in user_data['username'])\n",
    "        full_name_has_number = any(char.isdigit() for char in user_data['full_name'])\n",
    "        description_has_number = any(char.isdigit() for char in user_data['biography'])\n",
    "        \n",
    "        is_fake = True\n",
    "        \n",
    "        # row_numeric = {\n",
    "        #     'following': following,\n",
    "        #     'followers': followers,\n",
    "        #     'username_length': username_length,\n",
    "        #     'full_name_length': full_name_length, \n",
    "        #     'description_length': description_length, \n",
    "        #     'username_has_number': username_has_number, \n",
    "        #     'full_name_has_number': full_name_has_number,\n",
    "        #     'description_has_number': description_has_number, \n",
    "        #     'is_fake': is_fake\n",
    "        # }\n",
    "\n",
    "        # row_text = {\n",
    "        #     'username': username_text,\n",
    "        #     'full_name': full_name_text,\n",
    "        #     'description': description_text,\n",
    "        #     'is_fake': is_fake\n",
    "        # }\n",
    "\n",
    "        row_mix = {\n",
    "            'following': following,\n",
    "            'followers': followers,\n",
    "            'username_length': username_length,\n",
    "            'full_name_length': full_name_length,\n",
    "            'description_length': description_length,\n",
    "            'username_has_number': username_has_number,\n",
    "            'full_name_has_number': full_name_has_number,\n",
    "            'description_has_number': description_has_number,\n",
    "            'username': username_text,\n",
    "            'full_name': full_name_text,\n",
    "            'description': description_text,\n",
    "            'is_fake': is_fake\n",
    "        }\n",
    "        \n",
    "        # dataset_numeric = pd.concat([dataset_numeric, pd.DataFrame([row_numeric])], ignore_index=True)\n",
    "        # dataset_text = pd.concat([dataset_text, pd.DataFrame([row_text])], ignore_index=True)\n",
    "        dataset_mix = pd.concat([dataset_mix, pd.DataFrame([row_mix])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a1355-d417-4e7f-9ad2-828b6be80ca7",
   "metadata": {},
   "source": [
    "#### Process real account data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c825a7a-a7bb-4d72-bd6f-a1b1ada76bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.scandir('data/real'):\n",
    "    if filename.is_file():\n",
    "        real_data_file = open(filename.path)\n",
    "        real_json = json.load(real_data_file)\n",
    "\n",
    "        following = real_json['numberFollowing']\n",
    "        followers = real_json['numberFollowers']\n",
    "        \n",
    "        username_length = len(real_json['alias'])\n",
    "        username_has_number = any(char.isdigit() for char in real_json['alias'])\n",
    "        username_text = real_json['alias']\n",
    "        \n",
    "        full_name = real_json['username']\n",
    "        if full_name is not None:\n",
    "            full_name_length = len(full_name)\n",
    "            full_name_has_number = any(char.isdigit() for char in full_name)\n",
    "            full_name_text = full_name\n",
    "        else:\n",
    "            full_name_length = 0\n",
    "            full_name_has_number = False\n",
    "\n",
    "        description = real_json['descriptionProfile']\n",
    "        if description is not None:\n",
    "            description_length = len(description[0])\n",
    "            description_has_number = any(char.isdigit() for char in description[0])\n",
    "            description_text = description[0]\n",
    "        else:\n",
    "            description_length = 0\n",
    "            description_has_number = False\n",
    "\n",
    "        is_fake = False\n",
    "\n",
    "        # row_numeric = {\n",
    "        #     'following': following,\n",
    "        #     'followers': followers,\n",
    "        #     'username_length': username_length,\n",
    "        #     'full_name_length': full_name_length, \n",
    "        #     'description_length': description_length, \n",
    "        #     'username_has_number': username_has_number, \n",
    "        #     'full_name_has_number': full_name_has_number,\n",
    "        #     'description_has_number': description_has_number, \n",
    "        #     'is_fake': is_fake\n",
    "        # }\n",
    "\n",
    "        # row_text = {\n",
    "        #     'username': username_text,\n",
    "        #     'full_name': full_name_text,\n",
    "        #     'description': description_text,\n",
    "        #     'is_fake': is_fake\n",
    "        # }\n",
    "\n",
    "        row_mix = {\n",
    "            'following': following,\n",
    "            'followers': followers,\n",
    "            'username_length': username_length,\n",
    "            'full_name_length': full_name_length,\n",
    "            'description_length': description_length,\n",
    "            'username_has_number': username_has_number,\n",
    "            'full_name_has_number': full_name_has_number,\n",
    "            'description_has_number': description_has_number,\n",
    "            'username': username_text,\n",
    "            'full_name': full_name_text,\n",
    "            'description': description_text,\n",
    "            'is_fake': is_fake\n",
    "        }\n",
    "        \n",
    "        # dataset_numeric = pd.concat([dataset_numeric, pd.DataFrame([row_numeric])], ignore_index=True)\n",
    "        # dataset_text = pd.concat([dataset_text, pd.DataFrame([row_text])], ignore_index=True)\n",
    "        dataset_mix = pd.concat([dataset_mix, pd.DataFrame([row_mix])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75463a16-8845-4c9d-beb3-22d29f09585c",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a07cf-097c-4ea3-86a6-6d9cecf7a4ae",
   "metadata": {},
   "source": [
    "## Remove empty descriptions of the text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33352fda-f682-4ce6-82d5-5b14a10d84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_text = dataset_text[dataset_text['description'].str.len() > 0]\n",
    "dataset_mix = dataset_mix[dataset_mix['description'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d1d50-5bd6-4ce4-b492-254843b22e05",
   "metadata": {},
   "source": [
    "## Translate descriptions to english\n",
    "\n",
    "> Use wisely, API consumes money from google cloud free trial ($300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae01c429-64d8-4cf7-a6b2-83c8b26e5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# for index, row in dataset_text.iterrows():\n",
    "#     body = {\n",
    "#         'q': row['description'],\n",
    "#         'target': 'en',\n",
    "#         'key': 'AIzaSyAGzUMVuHzalVmFJsoBN9jyQZWHs2aY1Kg'\n",
    "#     }\n",
    "    \n",
    "#     res = requests.post('https://translation.googleapis.com/language/translate/v2?key=AIzaSyAGzUMVuHzalVmFJsoBN9jyQZWHs2aY1Kg', json=body)\n",
    "#     res_json = json.loads(res.text)\n",
    "#     translated_text = res_json['data']['translations'][0]['translatedText']\n",
    "\n",
    "#     cleaned_text = re.sub('[^a-zA-Z0-9\\s]', '', translated_text).lower()\n",
    "#     stop_words = list(set(stopwords.words('english')))\n",
    "#     word_tokens = word_tokenize(cleaned_text)\n",
    "#     array_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "#     lemmatized_tokens = [lemmatizer.lemmatize(word) for word in array_sentence]\n",
    "#     text = ' '.join(lemmatized_tokens)\n",
    "#     no_url_text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "\n",
    "#     dataset_text.at[index, 'description'] = no_url_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15074af5-887d-4d89-853f-95d494d26fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for index, row in dataset_mix.iterrows():\n",
    "    body = {\n",
    "        'q': row['description'],\n",
    "        'target': 'en',\n",
    "        'key': 'AIzaSyAGzUMVuHzalVmFJsoBN9jyQZWHs2aY1Kg'\n",
    "    }\n",
    "    \n",
    "    res = requests.post('https://translation.googleapis.com/language/translate/v2?key=AIzaSyAGzUMVuHzalVmFJsoBN9jyQZWHs2aY1Kg', json=body)\n",
    "    res_json = json.loads(res.text)\n",
    "    translated_text = res_json['data']['translations'][0]['translatedText']\n",
    "\n",
    "    cleaned_text = re.sub('[^a-zA-Z0-9\\s]', '', translated_text).lower()\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    word_tokens = word_tokenize(cleaned_text)\n",
    "    array_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in array_sentence]\n",
    "    text = ' '.join(lemmatized_tokens)\n",
    "    no_url_text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "\n",
    "    dataset_mix.at[index, 'description'] = no_url_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b5bda6-4d2b-4d34-ba69-b709c58a2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_text = dataset_text[dataset_text['description'].str.len() > 2]\n",
    "dataset_mix = dataset_mix[dataset_mix['description'].str.len() > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0e37e-818e-47f9-b6f3-4a65a53a790b",
   "metadata": {},
   "source": [
    "## Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28654ae3-6f85-4cbe-9898-6aa0815f8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = dataset_numeric.groupby('is_fake')\n",
    "# balanced_dataset_numeric = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "\n",
    "# g = dataset_text.groupby('is_fake')\n",
    "# balanced_dataset_text = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "\n",
    "g = dataset_mix.groupby('is_fake')\n",
    "balanced_dataset_mix = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d98bf8e-eb1a-4876-8c35-db43c3d1c0ac",
   "metadata": {},
   "source": [
    "## Split numeric and text datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c281a72-7916-4244-a7fe-e7405cc49029",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numeric = balanced_dataset_mix[['following', 'followers', 'username_length', 'full_name_length', 'description_length', 'username_has_number', 'full_name_has_number', 'description_has_number', 'is_fake']]\n",
    "dataset_text = balanced_dataset_mix[['username', 'full_name', 'description', 'is_fake']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795afca-b2b0-4d9f-bc95-8d97335685af",
   "metadata": {},
   "source": [
    "## Min-Max normalization of the numeric dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e0f236-57cf-4b3b-a712-a482f7dd0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_numeric = (dataset_numeric-dataset_numeric.min())/(dataset_numeric.max()-dataset_numeric.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af3853de-553c-47bb-8766-efa229c6e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>username_length</th>\n",
       "      <th>full_name_length</th>\n",
       "      <th>description_length</th>\n",
       "      <th>username_has_number</th>\n",
       "      <th>full_name_has_number</th>\n",
       "      <th>description_has_number</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_fake</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">False</th>\n",
       "      <th>0</th>\n",
       "      <td>0.072647</td>\n",
       "      <td>0.113159</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.550153</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039456</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07478</td>\n",
       "      <td>0.210061</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081445</td>\n",
       "      <td>0.041116</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">True</th>\n",
       "      <th>233</th>\n",
       "      <td>0.825913</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.144495</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.067982</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.109704</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.554385</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            following followers username_length full_name_length  \\\n",
       "is_fake                                                            \n",
       "False   0    0.072647  0.113159         0.26087         0.333333   \n",
       "        1    0.000267  0.550153        0.347826         0.866667   \n",
       "        2    0.039456  0.040202        0.391304         0.433333   \n",
       "        3     0.07478  0.210061        0.391304              0.4   \n",
       "        4    0.081445  0.041116        0.565217              0.5   \n",
       "...               ...       ...             ...              ...   \n",
       "True    233  0.825913  0.000012        0.478261              0.0   \n",
       "        234  0.144495  0.000005        0.347826              0.0   \n",
       "        235  0.067982  0.000002        0.304348              0.3   \n",
       "        236  0.109704  0.000006        0.391304              0.4   \n",
       "        237  0.554385  0.000132        0.521739         0.166667   \n",
       "\n",
       "            description_length username_has_number full_name_has_number  \\\n",
       "is_fake                                                                   \n",
       "False   0                 0.68                 0.0                  0.0   \n",
       "        1             0.306667                 0.0                  0.0   \n",
       "        2                 0.22                 0.0                  0.0   \n",
       "        3             0.473333                 0.0                  0.0   \n",
       "        4                 0.34                 0.0                  0.0   \n",
       "...                        ...                 ...                  ...   \n",
       "True    233           0.146667                 1.0                  0.0   \n",
       "        234           0.506667                 0.0                  0.0   \n",
       "        235           0.206667                 1.0                  0.0   \n",
       "        236           0.086667                 1.0                  1.0   \n",
       "        237           0.293333                 1.0                  0.0   \n",
       "\n",
       "            description_has_number is_fake  \n",
       "is_fake                                     \n",
       "False   0                      1.0     0.0  \n",
       "        1                      0.0     0.0  \n",
       "        2                      0.0     0.0  \n",
       "        3                      0.0     0.0  \n",
       "        4                      0.0     0.0  \n",
       "...                            ...     ...  \n",
       "True    233                    0.0     1.0  \n",
       "        234                    0.0     1.0  \n",
       "        235                    1.0     1.0  \n",
       "        236                    0.0     1.0  \n",
       "        237                    0.0     1.0  \n",
       "\n",
       "[476 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02c84c-80bc-4b5a-a348-f5b48d785c4c",
   "metadata": {},
   "source": [
    "# Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e71321-dc34-44b0-805f-6fee2afcf334",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset_mix.to_csv('data/dataset_mix.csv', index=False)\n",
    "dataset_numeric.to_csv('data/dataset_numeric.csv', index=False)\n",
    "dataset_text.to_csv('data/dataset_text.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
